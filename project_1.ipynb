{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Da fare\n",
    "1. Car model classification:\n",
    "   - entire car images vs **car parts**\n",
    "   - specific viewpoint vs all viewpoints\n",
    "2. **Car make classification**\n",
    "3. **Attribute Prediction:**\n",
    "   - Sum of square loss for continuous attributes\n",
    "   - Logistic loss for for discrete attributes\n",
    "   - Trained of the first set and tested on the second "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Module, Sequential, Conv2d, BatchNorm2d\n",
    "from torch.nn import SiLU as ReLU\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "from torchvision.transforms import Compose, ToTensor, RandomAffine, RandomHorizontalFlip, RandomVerticalFlip, ColorJitter, Resize\n",
    "import torch\n",
    "\n",
    "from dataset import *\n",
    "from utils import *\n",
    "from ResNet18_blocks import *\n",
    "from ResNet50_blocks import *\n",
    "from training_functions import *\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import utils\n",
    "# import dataset \n",
    "# import ResNet50_blocks \n",
    "# import ResNet18_blocks\n",
    "# importlib.reload(utils)\n",
    "# importlib.reload(dataset)\n",
    "# importlib.reload(ResNet18_blocks)\n",
    "# importlib.reload(ResNet50_blocks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDgcLN462u-1"
   },
   "source": [
    "# Neural Network and Deep Learning Project\n",
    "\n",
    "*Alberto Salvador, Volpi Gaia*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "_V2RXqilaw49",
    "outputId": "e1483d51-65dd-470d-b319-84f1e7225a9b"
   },
   "outputs": [],
   "source": [
    "#volume_dir = \"/mnt/shared_volume/\"\n",
    "volume_dir = \"/mnt/home/u0053/disk/gaia_dataset/CompCars/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder inside volume dir \n",
    "for vp in range(6):\n",
    "    if not os.path.exists(volume_dir + f'{vp}/'):\n",
    "        os.makedirs(volume_dir + f'{vp}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "0HwsecSe8bDT",
    "outputId": "eeef1e8b-ac1c-4ee6-9b82-6cf714acbc94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/mnt/shared_volume/data/train_test_split/classification': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! ls /mnt/shared_volume/data/train_test_split/classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vxGKKCY14DF"
   },
   "source": [
    "## 1. Dataset\n",
    "\n",
    "Qui sotto si crea il dataset per fare il training su tutti i viewpoints!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of models in the train dataset:  431\n"
     ]
    }
   ],
   "source": [
    "label_to_index = indexing_labels(volume_dir+\"data/train_test_split/classification/train.txt\")\n",
    "print(\"Nr of models in the train dataset: \", len(label_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = Compose([\n",
    "    Resize((224, 224)), \n",
    "    ToTensor(), #this converts numpy or Pil image to torch tensor and normalizes it in 0, 1\n",
    "    RandomAffine((0.05, 0.05)),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomVerticalFlip()\n",
    "])\n",
    "\n",
    "transforms = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "51W3vn_cB3iC"
   },
   "outputs": [],
   "source": [
    "label_type = 'model_id' # 'model_id' or 'make_id'\n",
    "make_dataset = dataset_factory(volume_dir, label_to_index, transforms_train, transforms, label_type=label_type) # serve per creare la factory che genera i dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEWPOINT = None\n",
    "train_dataset, test_dataset, valid_dataset =  make_dataset(VIEWPOINT) # carino perchÃ¨ devi passare solo il viewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "NjVO575OCR4r",
    "outputId": "004cef8f-c9b5-48b3-96cd-9d8d1bf73531"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m16\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     axs[i\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m][i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mvalid_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m      4\u001b[0m     axs[i\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m][i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xticks([])\n\u001b[1;32m      5\u001b[0m     axs[i\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m][i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mset_yticks([])\n",
      "File \u001b[0;32m/mnt/projects/dei/most/u0053/gaia/dataset.py:157\u001b[0m, in \u001b[0;36mImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m--> 157\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    158\u001b[0m     image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict_labels[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx])] \u001b[38;5;66;03m#labelling the image, converting the original label to index through the dictionary\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(4, 4, figsize=(6,6))\n",
    "for i in range(16):\n",
    "    axs[i//4][i%4].imshow(train_dataset[i][0].permute(1, 2, 0).numpy())\n",
    "    axs[i//4][i%4].set_xticks([])\n",
    "    axs[i//4][i%4].set_yticks([])\n",
    "    axs[i//4][i%4].set_title(f\"{train_dataset[i][1]}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bjHs8vuG6eq",
    "outputId": "dff480a3-6c13-4a7b-b243-9a07fbe31733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: 16016 \n",
      "test dataset: 7576 \n",
      "valid dataset: 7363\n"
     ]
    }
   ],
   "source": [
    "print(f'train dataset: {len(train_dataset)} \\ntest dataset: {len(test_dataset)} \\nvalid dataset: {len(valid_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIEWPOINT: None\n",
      "\ttrain dataset: 16016 \ttest dataset: 7576 \tvalid dataset: 7363\n",
      "VIEWPOINT: 1\n",
      "\ttrain dataset: 2593 \ttest dataset: 0 \tvalid dataset: 2381\n",
      "VIEWPOINT: 2\n",
      "\ttrain dataset: 1997 \ttest dataset: 0 \tvalid dataset: 1794\n",
      "VIEWPOINT: 3\n",
      "\ttrain dataset: 2973 \ttest dataset: 177 \tvalid dataset: 2572\n",
      "VIEWPOINT: 4\n",
      "\ttrain dataset: 4828 \ttest dataset: 3990 \tvalid dataset: 616\n",
      "VIEWPOINT: 5\n",
      "\ttrain dataset: 3625 \ttest dataset: 3409 \tvalid dataset: 0\n"
     ]
    }
   ],
   "source": [
    "for VIEWPOINT in [None,1,2,3,4,5]:\n",
    "    print(f\"VIEWPOINT: {VIEWPOINT}\")\n",
    "    train_dataset, test_dataset, valid_dataset =  make_dataset(VIEWPOINT) # carino perchÃ¨ devi passare solo il viewpoint\n",
    "    print(f'\\ttrain dataset: {len(train_dataset)} \\ttest dataset: {len(test_dataset)} \\tvalid dataset: {len(valid_dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0SBtLucZ-xgT"
   },
   "outputs": [],
   "source": [
    "# Here we use the Dataloader function from pytorch to opportunely split the dataset in batches and shuffling data\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "valid_dataloader = DataLoader(valid_dataset, os.cpu_count()*2, shuffle=False, num_workers=os.cpu_count())\n",
    "test_dataloader = DataLoader(test_dataset, os.cpu_count()*2, shuffle=False, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class weights\n",
    "# labels_array = []\n",
    "# for batch in train_dataloader:\n",
    "#     _, labels = batch\n",
    "#     labels_array.append(labels)\n",
    "# labels_array = torch.cat(labels_array).numpy().astype(int)\n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels_array), y=labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#check_unbalance_dataset(valid_dataloader, n_indices=3000, title='validation set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#check_unbalance_dataset(train_dataloader, n_indices=3000, title='training set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#check_unbalance_dataset(valid_dataloader, n_indices=3000, title='valid set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9H22d0w008G"
   },
   "source": [
    "## 2. Training \n",
    "\n",
    "We have implemented two different architectures:\n",
    "- ResNet50\n",
    "- ResNet 18\n",
    "\n",
    "We will proceed with ResNet18 now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ResNet18()\n",
    "loss = CrossEntropyLoss\n",
    "epochs = 200\n",
    "\n",
    "#optimizer = Adam(params=model.parameters(), lr=3e-4, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training on all viewpoints\n",
    "when: vp=None or '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 6.2494 - Acc: 0.2:   7%|â         | 17/251 [00:06<01:32,  2.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#weight_decays = [1e-5, 1e-4, 5e-4]\u001b[39;00m\n\u001b[1;32m      2\u001b[0m wd \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m\n\u001b[0;32m----> 3\u001b[0m train_loss_log, val_loss_log, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43mvalid_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43mload_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvolume_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvolume_dir\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfix_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalcul_class_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43msave_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVIEWPOINT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvolume_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43msave_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVIEWPOINT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plot_losses(train_loss_log, val_loss_log, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/projects/dei/most/u0053/gaia/training_functions.py:144\u001b[0m, in \u001b[0;36mnetwork_training\u001b[0;34m(train_dataloader, valid_dataloader, load_checkpoint, loss_fn, device, save_checkpoint, save_metric, epochs)\u001b[0m\n\u001b[1;32m    140\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# backpropagation\u001b[39;00m\n\u001b[1;32m    142\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# update the weights\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m loss_batch \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    145\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(loss_batch)\n\u001b[1;32m    147\u001b[0m accuracies\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    148\u001b[0m     ((y_pred\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m batch_y)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;66;03m# compute accuracy for this batch\u001b[39;00m\n\u001b[1;32m    149\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#weight_decays = [1e-5, 1e-4, 5e-4]\n",
    "wd = 1e-4\n",
    "train_loss_log, val_loss_log, _ = network_training(\n",
    "train_dataloader=train_dataloader, \n",
    "valid_dataloader=valid_dataloader,\n",
    "load_checkpoint=load_checkpoint(\n",
    "    load=False, \n",
    "    model=model,\n",
    "    opt=Adam(params=model.parameters(), lr=3e-4, weight_decay=wd), \n",
    "    device=device, \n",
    "    volume_dir=volume_dir\n",
    "),\n",
    "loss_fn=fix_losses(calcul_class_weights(train_dataloader), CrossEntropyLoss, device),\n",
    "device=device,\n",
    "epochs=epochs,\n",
    "save_checkpoint=lambda model, opt: save_checkpoint(model, opt, VIEWPOINT or \"0\", volume_dir),\n",
    "save_metric=lambda metric, values: store_metric(volume_dir)(metric, values, VIEWPOINT)\n",
    ")\n",
    "\n",
    "fig, ax = plot_losses(train_loss_log, val_loss_log, save=True)\n",
    "ax.set_title(f\"weight_decay={wd}\")\n",
    "plt.savefig(volume_dir + \"gridsearch/\"+f\"losses_wd{wd}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), volume_dir+'0'+\"/model_1.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_log = np.loadtxt(volume_dir+str(VIEWPOINT or '0')+'/train_loss_log.txt').tolist()\n",
    "val_loss_log = np.loadtxt(volume_dir+str(VIEWPOINT or '0')+'/val_loss_log.txt').tolist()\n",
    "plot_losses(train_loss_log, val_loss_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training on different viewpoints (label_type='model_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 5.9677 - Acc: 0.3: 100%|ââââââââââ| 76/76 [00:14<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation...\n",
      "valid_dataloader  616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]Exception ignored in: <function _releaseLock at 0x7fcce9111b40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/home/u0053/.conda/envs/alberto/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "  0%|          | 0/4 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 278390, 278391, 278392, 278393, 278394, 278395, 278396, 278397, 278398, 278399, 278400, 278401, 278402, 278403, 278404, 278405, 278406, 278407, 278408, 278409, 278410, 278411, 278412, 278413, 278414, 278415, 278416, 278417, 278418, 278419, 278420, 278421, 278422, 278423, 278424, 278425, 278426, 278427, 278428, 278429, 278430, 278431, 278432, 278433, 278434, 278435, 278436, 278437, 278438, 278439, 278440, 278441, 278442, 278443, 278444, 278445, 278446, 278447, 278448, 278449, 278451) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/.conda/envs/alberto/lib/python3.10/multiprocessing/queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(params\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-4\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_viewpoint_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mviewpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmake_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvolume_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvolume_dir\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mviewpoint\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mviewpoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvolume_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_pretrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvp\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mload_pretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_type\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/projects/dei/most/u0053/gaia/training_functions.py:263\u001b[0m, in \u001b[0;36mmulti_viewpoint_training\u001b[0;34m(viewpoints, epochs, make_dataset, load_checkpoint, loss_fn, device, save_checkpoint, save_metric, model_class, load_pretrain, k_list, label_type)\u001b[0m\n\u001b[1;32m    260\u001b[0m model \u001b[38;5;241m=\u001b[39m model_class() \u001b[38;5;66;03m# per rinizializzare il modello ad ogni iterazione altrimenti buuuuu\u001b[39;00m\n\u001b[1;32m    262\u001b[0m class_weight \u001b[38;5;241m=\u001b[39m calcul_class_weights(train_dataloader)\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;241m*\u001b[39m_, model \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m#model, *_ = load_pretrain(device, model, vp=0)\u001b[39;00m\n\u001b[1;32m    275\u001b[0m topk_score \u001b[38;5;241m=\u001b[39m evaluate_network(test_dataloader, model, k_list, device)\n",
      "File \u001b[0;32m/mnt/projects/dei/most/u0053/gaia/training_functions.py:165\u001b[0m, in \u001b[0;36mnetwork_training\u001b[0;34m(train_dataloader, valid_dataloader, load_checkpoint, loss_fn, device, save_checkpoint, save_metric, epochs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting validation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_dataloader \u001b[39m\u001b[38;5;124m\"\u001b[39m, valid_dataloader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m())\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m tqdm(valid_dataloader):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_x, batch_y loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m     batch_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/alberto/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1491\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1453\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1453\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1455\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1297\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1296\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 278390, 278391, 278392, 278393, 278394, 278395, 278396, 278397, 278398, 278399, 278400, 278401, 278402, 278403, 278404, 278405, 278406, 278407, 278408, 278409, 278410, 278411, 278412, 278413, 278414, 278415, 278416, 278417, 278418, 278419, 278420, 278421, 278422, 278423, 278424, 278425, 278426, 278427, 278428, 278429, 278430, 278431, 278432, 278433, 278434, 278435, 278436, 278437, 278438, 278439, 278440, 278441, 278442, 278443, 278444, 278445, 278446, 278447, 278448, 278449, 278451) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "label_type = 'model_id' # 'model_id' or 'make_id'\n",
    "\n",
    "optimizer = Adam(params=model.parameters(), lr=3e-4, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "metrics = multi_viewpoint_training(\n",
    "    viewpoints=[5], \n",
    "    epochs=epochs, \n",
    "    make_dataset=make_dataset,\n",
    "    load_checkpoint=load_checkpoint(\n",
    "        load=False, \n",
    "        model=model,\n",
    "        opt=optimizer, \n",
    "        device=device, \n",
    "        volume_dir=volume_dir\n",
    "    ), \n",
    "    loss_fn=lambda class_weights: fix_losses(class_weights, loss, device), \n",
    "    device=device, \n",
    "    save_checkpoint=lambda model, opt, viewpoint: save_checkpoint(model, opt, viewpoint or \"0\", volume_dir), \n",
    "    load_pretrain=lambda device, model, vp :load_pretrain(volume_dir, device, model, None, vp=vp),\n",
    "    save_metric=store_metric(volume_dir), \n",
    "    model_class=type(model), \n",
    "    k_list=[1,5], \n",
    "    label_type=label_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training on different viewpoints (label_type='make_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'make_id' # 'model_id' or 'make_id'\n",
    "\n",
    "optimizer = Adam(params=model.parameters(), lr=3e-4, weight_decay=0.0001)\n",
    "\n",
    "metrics = multi_viewpoint_training(\n",
    "    viewpoints=[5], \n",
    "    epochs=epochs, \n",
    "    make_dataset=make_dataset,\n",
    "    load_checkpoint=load_checkpoint(\n",
    "        load=False, \n",
    "        model=model,\n",
    "        opt=optimizer, \n",
    "        device=device, \n",
    "        volume_dir=volume_dir\n",
    "    ), \n",
    "    loss_fn=lambda class_weights: fix_losses(class_weights, loss, device), \n",
    "    device=device, \n",
    "    save_checkpoint=lambda model, opt, viewpoint: save_checkpoint(model, opt, viewpoint or \"0\", volume_dir), \n",
    "    load_pretrain=lambda device, model, vp :load_pretrain(volume_dir, device, model, None, vp=vp),\n",
    "    save_metric=store_metric(volume_dir), \n",
    "    model_class=type(model), \n",
    "    k_list=[1,5], \n",
    "    label_type=label_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the table with all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab3 = table3(folder_path=volume_dir + 'table3/')\n",
    "tab3"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python alberto env",
   "language": "python",
   "name": "alberto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
